import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer

"""
üí¨ SENTIMENT ANALYSIS: Teaching Machines to Read Emotions

Amazon: "Is this review positive or negative?"
Twitter: "How do people feel about our brand?"
Customer Service: "Which complaints are urgent?"

This is NLP solving real problems.
"""

print("="*70)
print("üí¨ SENTIMENT ANALYSIS: Real-World NLP Application")
print("="*70)

# ===== STEP 1: Create Realistic Dataset =====
print("\nüìä STEP 1: Building Health Review Dataset")
print("-" * 70)

# Realistic health app reviews
reviews_data = {
    'review': [
        # POSITIVE reviews
        "This health app is amazing! Helped me lose 15 pounds in 2 months. Highly recommend!",
        "Love the workout tracking feature. Very intuitive and motivating. Best health app ever!",
        "Excellent nutrition advice and meal planning. My energy levels have improved significantly.",
        "The sleep tracker is incredibly accurate. Finally understanding my sleep patterns!",
        "Outstanding app! The AI coach provides personalized recommendations. Worth every penny.",
        "Great interface, helpful reminders, and fantastic progress tracking. Five stars!",
        "This app changed my life. Down 20 pounds and feeling healthier than ever.",
        "Wonderful experience. The community support feature is incredibly motivating.",
        "Best investment in my health. The guided meditations are perfect for stress relief.",
        "Impressive accuracy in calorie tracking. Makes healthy eating so much easier.",

        # NEGATIVE reviews
        "Terrible app. Crashes constantly and lost all my progress data. Very frustrating!",
        "Waste of money. Features don't work as advertised. Customer support is non-existent.",
        "Disappointed. The app drains my battery within hours. Unusable.",
        "Horrible experience. Inaccurate calorie counts and confusing interface. Do not download!",
        "Awful. Tried to cancel subscription but kept getting charged. Poor business practices.",
        "Worst health app I've used. Buggy, slow, and provides incorrect fitness advice.",
        "Complete garbage. The workout tracker doesn't sync and loses data randomly.",
        "Frustrating! App freezes during workouts. Missed several important health metrics.",
        "Disappointing. Paid for premium but features are worse than free alternatives.",
        "Useless. The meal planner suggests impossible recipes. Waste of time and money.",

        # NEUTRAL reviews
        "It's okay. Does the basic job but nothing special. Average health tracking.",
        "Decent app. Works as described but could use more features.",
        "Acceptable for free version. Premium features not worth the upgrade.",
        "Standard health tracker. Nothing innovative but gets the job done.",
        "Mediocre. Some features work well, others are buggy. Mixed experience.",
        "Average app. Good for beginners but advanced users will want more.",
        "It works. Not amazing, not terrible. Just adequate for basic tracking.",
        "Fair app. Some useful features but interface could be more intuitive.",
        "Acceptable for casual users. Serious athletes will need something better.",
        "Middle-of-the-road app. Does what it says but doesn't exceed expectations."
    ],
    'sentiment': [
        'positive'] * 10 + ['negative'] * 10 + ['neutral'] * 10
}

df = pd.DataFrame(reviews_data)
print(f"Dataset: {len(df)} health app reviews")
print("\nSentiment distribution:")
print(df['sentiment'].value_counts())
print("\nSample reviews:")
print(df.head(3)[['review', 'sentiment']])

# ===== STEP 2: Text Preprocessing Pipeline =====
print("\n\nüßπ STEP 2: Preprocessing Pipeline")
print("-" * 70)

lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_review(text):
    """Complete preprocessing pipeline"""
    # Lowercase
    text = text.lower()

    # Remove special characters but keep basic punctuation for sentiment
    text = re.sub(r'[^a-zA-Z\s!?]', '', text)

    # Tokenize
    tokens = word_tokenize(text)

    # Remove stop words (but keep negations!)
    negations = ['not', 'no', 'never', 'neither', 'nobody', 'nowhere']
    tokens = [w for w in tokens if w not in stop_words or w in negations]

    # Lemmatize
    tokens = [lemmatizer.lemmatize(w, pos='v') for w in tokens]

    return ' '.join(tokens)

df['processed'] = df['review'].apply(preprocess_review)

print("Example preprocessing:")
print("-" * 70)
for i in range(3):
    print(f"\nOriginal: {df['review'].iloc[i]}")
    print(f"Processed: {df['processed'].iloc[i]}")

print("\nüí° PRESERVED:")
print("   Negations ('not', 'never') - crucial for sentiment!")
print("   Exclamation marks - indicate strong emotion")

# ===== STEP 3: TF-IDF Vectorization =====
print("\n\nüìä STEP 3: Converting Text to Numbers (TF-IDF)")
print("-" * 70)

# Split data
X = df['processed']
y = df['sentiment']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

print(f"Training set: {len(X_train)} reviews")
print(f"Test set: {len(X_test)} reviews")

# TF-IDF vectorization
tfidf = TfidfVectorizer(max_features=500, ngram_range=(1, 2))
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

print(f"\nVocabulary size: {len(tfidf.get_feature_names_out())}")
print(f"Matrix shape: {X_train_tfidf.shape}")

# Show most important features
feature_names = tfidf.get_feature_names_out()
print(f"\nSample features (including bigrams):")
print(feature_names[:20])

# ===== STEP 4: Train Multiple Models =====
print("\n\nüéì STEP 4: Training Sentiment Classifiers")
print("-" * 70)

# Model 1: Naive Bayes (classic for text)
nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)
nb_pred = nb_model.predict(X_test_tfidf)
nb_accuracy = accuracy_score(y_test, nb_pred)

print(f"\n1Ô∏è‚É£  Naive Bayes Accuracy: {nb_accuracy*100:.2f}%")

# Model 2: Logistic Regression
lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train_tfidf, y_train)
lr_pred = lr_model.predict(X_test_tfidf)
lr_accuracy = accuracy_score(y_test, lr_pred)

print(f"2Ô∏è‚É£  Logistic Regression Accuracy: {lr_accuracy*100:.2f}%")

# Choose best model
best_model = lr_model if lr_accuracy > nb_accuracy else nb_model
best_pred = lr_pred if lr_accuracy > nb_accuracy else nb_pred
best_name = "Logistic Regression" if lr_accuracy > nb_accuracy else "Naive Bayes"

print(f"\n‚úÖ Best model: {best_name} ({max(lr_accuracy, nb_accuracy)*100:.2f}%)")

# ===== STEP 5: Detailed Evaluation =====
print("\n\nüìà STEP 5: Model Evaluation")
print("-" * 70)

print("\nClassification Report:")
print(classification_report(y_test, best_pred, digits=3))

# Confusion Matrix
cm = confusion_matrix(y_test, best_pred, labels=['positive', 'neutral', 'negative'])
print("\nConfusion Matrix:")
print("                Predicted")
print("              Pos  Neu  Neg")
print(f"Actual Pos:   {cm[0]}")
print(f"       Neu:   {cm[1]}")
print(f"       Neg:   {cm[2]}")

print("\nüí° INTERPRETATION:")
print("   Precision: Of predicted positives, how many were actually positive?")
print("   Recall: Of actual positives, how many did we find?")
print("   F1-Score: Harmonic mean of precision and recall")

# ===== STEP 6: Feature Importance - What Words Matter? =====
print("\n\nüîç STEP 6: What Words Indicate Sentiment?")
print("-" * 70)

# Get feature weights from Logistic Regression
if best_name == "Logistic Regression":
    # For multi-class, get coefficients for each class
    feature_names = tfidf.get_feature_names_out()

    # Positive indicators
    pos_coeffs = lr_model.coef_[lr_model.classes_ == 'positive'][0]
    top_positive = sorted(zip(feature_names, pos_coeffs), key=lambda x: x[1], reverse=True)[:10]

    # Negative indicators
    neg_coeffs = lr_model.coef_[lr_model.classes_ == 'negative'][0]
    top_negative = sorted(zip(feature_names, neg_coeffs), key=lambda x: x[1], reverse=True)[:10]

    print("\n‚úÖ Words that predict POSITIVE sentiment:")
    for word, score in top_positive:
        print(f"   {word:20s}: {score:6.3f}")

    print("\n‚ùå Words that predict NEGATIVE sentiment:")
    for word, score in top_negative:
        print(f"   {word:20s}: {score:6.3f}")

print("\nüí° INSIGHTS:")
print("   'amazing', 'excellent', 'love' ‚Üí strongly positive")
print("   'terrible', 'waste', 'awful' ‚Üí strongly negative")
print("   'not good', 'not work' ‚Üí bigrams capture negation!")

# ===== STEP 7: Real-Time Sentiment Prediction =====
print("\n\nüîÆ STEP 7: Predicting Sentiment of New Reviews")
print("-" * 70)

new_reviews = [
    "This app is absolutely fantastic! Changed my entire fitness routine.",
    "Horrible experience. App crashes every time I try to log meals.",
    "It's okay, nothing special. Does basic tracking.",
    "Terrible customer service and buggy interface. Waste of money!",
    "Love the meditation features! Very calming and well-designed."
]

print("Analyzing new reviews:")
print("=" * 70)

for i, review in enumerate(new_reviews, 1):
    # Preprocess
    processed = preprocess_review(review)

    # Vectorize
    review_tfidf = tfidf.transform([processed])

    # Predict
    sentiment = best_model.predict(review_tfidf)[0]
    confidence = np.max(best_model.predict_proba(review_tfidf))

    # Get all probabilities
    proba = best_model.predict_proba(review_tfidf)[0]
    classes = best_model.classes_

    print(f"\n{i}. Review: {review}")
    print(f"   Sentiment: {sentiment.upper()} (confidence: {confidence*100:.1f}%)")
    print(f"   Probabilities:")
    for cls, prob in zip(classes, proba):
        print(f"      {cls:10s}: {prob*100:5.1f}%")

# ===== STEP 8: Visualization =====
print("\n\nüìä STEP 8: Visualizing Results")
print("-" * 70)

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Plot 1: Confusion Matrix Heatmap
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
           xticklabels=['Positive', 'Neutral', 'Negative'],
           yticklabels=['Positive', 'Neutral', 'Negative'],
           ax=axes[0])
axes[0].set_xlabel('Predicted Sentiment', fontsize=12)
axes[0].set_ylabel('Actual Sentiment', fontsize=12)
axes[0].set_title(f'Sentiment Analysis Confusion Matrix\n{best_name}',
                 fontsize=13, fontweight='bold')

# Plot 2: Model Comparison
models = ['Naive Bayes', 'Logistic Regression']
accuracies = [nb_accuracy, lr_accuracy]
colors = ['skyblue', 'lightcoral']

axes[1].bar(models, accuracies, color=colors, alpha=0.7, edgecolor='black')
axes[1].set_ylabel('Accuracy', fontsize=12)
axes[1].set_title('Model Performance Comparison', fontsize=13, fontweight='bold')
axes[1].set_ylim([0, 1])
axes[1].grid(True, alpha=0.3, axis='y')

for i, acc in enumerate(accuracies):
    axes[1].text(i, acc + 0.02, f'{acc*100:.1f}%',
                ha='center', fontweight='bold')

plt.tight_layout()
plt.savefig('sentiment_analysis_results.png', dpi=150, bbox_inches='tight')
print("Visualization saved: sentiment_analysis_results.png")

print("\n" + "="*70)
print("üéâ SENTIMENT ANALYSIS COMPLETE!")
print("="*70)
print("\nWhat you built:")
print("   ‚úì Complete text preprocessing pipeline")
print("   ‚úì TF-IDF vectorization with bigrams")
print("   ‚úì Multi-class sentiment classifier")
print("   ‚úì Model evaluation & interpretation")
print("   ‚úì Real-time sentiment prediction")
print("\nüí° REAL-WORLD APPLICATIONS:")
print("   ‚Ä¢ Amazon: Analyze millions of product reviews")
print("   ‚Ä¢ Twitter: Track brand sentiment in real-time")
print("   ‚Ä¢ Customer Service: Prioritize negative feedback")
print("   ‚Ä¢ Healthcare: Monitor patient feedback sentiment")
print("   ‚Ä¢ Finance: Analyze news sentiment for trading")
print("\nüöÄ This is production-grade NLP!")
print("   From ELIZA's illusion to real understanding")
print("   From pattern matching to geometric meaning")
print("   You've mastered the journey!")
