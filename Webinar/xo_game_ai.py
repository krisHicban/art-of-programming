"""
ğŸ§  X È™i O cu InteligenÈ›Äƒ ArtificialÄƒ prin Machine Learning (Q-Learning)
================================================================================

Acest script demonstreazÄƒ diferenÈ›a dintre:
1. AI simplu cu reguli fixe (cum am vÄƒzut Ã®n xo_game.py)
2. AI cu Machine Learning care "Ã®nvaÈ›Äƒ" prin experienÈ›Äƒ

ğŸ¯ CONCEPTE EDUCAÈšIONALE CHEIE:
- Q-Learning: Algoritmul Ã®nvaÈ›Äƒ prin Ã®ncercare È™i eroare
- Exploration vs Exploitation: ExploreazÄƒ strategii noi vs foloseÈ™te ce È™tie
- Reward System: ÃnvaÈ›Äƒ din recompense (+1 cÃ¢È™tig, -1 pierdere)
- Q-Table: "Memoria" AI-ului - ce sÄƒ facÄƒ Ã®n fiecare situaÈ›ie

ğŸ” DIFERENÈšA FUNDAMENTALÄ‚:
- AI simplu: "DacÄƒ pot cÃ¢È™tiga â†’ cÃ¢È™tig, dacÄƒ trebuie sÄƒ blochez â†’ blochez"
- AI cu ML: "Am Ã®ncercat aceastÄƒ mutare Ã®nainte È™i am cÃ¢È™tigat/pierdut,
            deci o sÄƒ o Ã®ncerc din nou/evit"

Autori: Neo & Claude - Webinar "Arta ProgramÄƒrii"
"""

import sys
import random
import pickle
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict, deque
import time
from PyQt5.QtWidgets import (QApplication, QWidget, QVBoxLayout, QHBoxLayout,
                            QPushButton, QLabel, QDialog, QTextEdit, QFrame,
                            QScrollArea, QGridLayout, QSplitter, QProgressBar,
                            QTabWidget, QTableWidget, QTableWidgetItem)
from PyQt5.QtGui import QFont, QPalette
from PyQt5.QtCore import Qt, QTimer, QThread, pyqtSignal


class QLearningAgent:
    """
    ğŸ§  AGENTUL Q-LEARNING - "Creierul" AI-ului care Ã®nvaÈ›Äƒ

    Concepte cheie:
    - Q-Table: DicÈ›ionar cu situaÈ›ii de joc È™i ce sÄƒ facÄƒ
    - Epsilon (Îµ): CÃ¢t de mult exploreazÄƒ vs foloseÈ™te ce È™tie
    - Learning Rate (Î±): CÃ¢t de repede Ã®nvaÈ›Äƒ din experienÈ›e noi
    - Discount Factor (Î³): CÃ¢t de mult valoreazÄƒ recompensele viitoare
    """

    def __init__(self, learning_rate=0.1, discount_factor=0.95, epsilon=0.1):
        # ğŸ“š Q-Table: Memoria AI-ului - pentru fiecare (situaÈ›ie, acÈ›iune)
        # pÄƒstreazÄƒ o valoare Q care spune cÃ¢t de bunÄƒ e acea acÈ›iune
        self.q_table = defaultdict(float)

        # ğŸ“ Parametrii de Ã®nvÄƒÈ›are
        self.learning_rate = learning_rate      # Î± - cÃ¢t de repede Ã®nvaÈ›Äƒ (0.1 = Ã®ncet dar sigur)
        self.discount_factor = discount_factor  # Î³ - importanÈ›a viitorului (0.95 = se gÃ¢ndeÈ™te la viitor)
        self.epsilon = epsilon                  # Îµ - cÃ¢t exploreazÄƒ (0.1 = 10% explorare, 90% foloseÈ™te ce È™tie)

        # ğŸ“Š Statistici pentru monitorizare
        self.total_games = 0
        self.wins = 0
        self.losses = 0
        self.draws = 0

        # ğŸ¯ Pentru debugging È™i educaÈ›ie
        self.last_state = None
        self.last_action = None
        self.decision_reason = ""

    def state_to_string(self, board):
        """
        ğŸ”„ ConverteÈ™te tabla de joc Ã®ntr-un string pentru Q-table

        De ce string? Pentru cÄƒ Q-table-ul are nevoie de chei immutable
        Exemplu: ['X', '', 'O', '', 'X', '', '', '', ''] â†’ "X_O_X____"
        """
        return ''.join(board).replace(' ', '_')

    def get_valid_actions(self, board):
        """
        ğŸ¯ GÄƒseÈ™te toate miÈ™cÄƒrile posibile (poziÈ›iile libere)
        """
        return [i for i, cell in enumerate(board) if cell == '']

    def choose_action(self, board, training=True):
        """
        ğŸ¤” DECIZIA PRINCIPALÄ‚: Ce miÈ™care sÄƒ fac?

        FoloseÈ™te strategia Îµ-greedy:
        - Cu probabilitatea Îµ: EXPLOREAZÄ‚ (Ã®ncearcÄƒ ceva nou/random)
        - Cu probabilitatea 1-Îµ: EXPLOATEAZÄ‚ (foloseÈ™te cea mai bunÄƒ miÈ™care cunoscutÄƒ)

        Acest echilibru este ESENÈšIAL Ã®n ML!
        """
        state = self.state_to_string(board)
        valid_actions = self.get_valid_actions(board)

        if not valid_actions:
            return None

        # ğŸ² EXPLORARE vs EXPLOATARE
        if training and random.random() < self.epsilon:
            # EXPLORARE: ÃncearcÄƒ ceva nou!
            action = random.choice(valid_actions)
            self.decision_reason = f"ğŸ² EXPLORARE: Ãncerc poziÈ›ia {action + 1} la Ã®ntÃ¢mplare (Îµ={self.epsilon:.2f})"
        else:
            # EXPLOATARE: FoloseÈ™te cea mai bunÄƒ miÈ™care cunoscutÄƒ
            q_values = {action: self.q_table[(state, action)] for action in valid_actions}
            max_q = max(q_values.values())

            # DacÄƒ sunt mai multe acÈ›iuni cu aceeaÈ™i valoare Q maximÄƒ, alege random dintre ele
            best_actions = [action for action, q_val in q_values.items() if q_val == max_q]
            action = random.choice(best_actions)

            self.decision_reason = f"ğŸ§  EXPLOATARE: Aleg poziÈ›ia {action + 1} (Q-value: {max_q:.3f})"

        self.last_state = state
        self.last_action = action
        return action

    def update_q_value(self, reward, next_board=None):
        """
        ğŸ“ ÃNVÄ‚ÈšAREA PROPRIU-ZISÄ‚: ActualizeazÄƒ Q-Table-ul

        Formula Q-Learning:
        Q(s,a) = Q(s,a) + Î±[r + Î³*max(Q(s',a')) - Q(s,a)]

        Traducere Ã®n romÃ¢nÄƒ:
        "Valoarea noua = Valoarea veche + rata_invatare * [recompensa + discount * cea_mai_buna_mutare_viitoare - valoarea_veche]"
        """
        if self.last_state is None or self.last_action is None:
            return

        current_q = self.q_table[(self.last_state, self.last_action)]

        # CalculeazÄƒ cea mai bunÄƒ valoare Q pentru starea urmÄƒtoare
        if next_board is not None:
            next_state = self.state_to_string(next_board)
            next_valid_actions = self.get_valid_actions(next_board)
            if next_valid_actions:
                max_next_q = max(self.q_table[(next_state, action)] for action in next_valid_actions)
            else:
                max_next_q = 0
        else:
            max_next_q = 0  # Jocul s-a terminat

        # ğŸ§® FORMULA MAGICÄ‚ Q-LEARNING
        new_q = current_q + self.learning_rate * (reward + self.discount_factor * max_next_q - current_q)
        self.q_table[(self.last_state, self.last_action)] = new_q

    def game_ended(self, reward):
        """
        ğŸ Jocul s-a terminat - Ã®nvaÈ›Äƒ din rezultat
        """
        self.update_q_value(reward)
        self.total_games += 1

        if reward > 0:
            self.wins += 1
        elif reward < 0:
            self.losses += 1
        else:
            self.draws += 1

        # Reset pentru urmÄƒtorul joc
        self.last_state = None
        self.last_action = None

    def get_statistics(self):
        """
        ğŸ“Š Statistici pentru monitorizarea progresului
        """
        if self.total_games == 0:
            return {"total": 0, "win_rate": 0, "loss_rate": 0, "draw_rate": 0}

        return {
            "total": self.total_games,
            "wins": self.wins,
            "losses": self.losses,
            "draws": self.draws,
            "win_rate": self.wins / self.total_games,
            "loss_rate": self.losses / self.total_games,
            "draw_rate": self.draws / self.total_games
        }

    def save_model(self, filename):
        """
        ğŸ’¾ SalveazÄƒ "creierul" antrenat
        """
        with open(filename, 'wb') as f:
            pickle.dump({
                'q_table': dict(self.q_table),
                'stats': self.get_statistics(),
                'params': {
                    'learning_rate': self.learning_rate,
                    'discount_factor': self.discount_factor,
                    'epsilon': self.epsilon
                }
            }, f)

    def load_model(self, filename):
        """
        ğŸ“ ÃncarcÄƒ un "creier" antrenat anterior
        """
        try:
            with open(filename, 'rb') as f:
                data = pickle.load(f)
                self.q_table = defaultdict(float, data['q_table'])
                stats = data['stats']
                self.total_games = stats['total']
                self.wins = stats['wins']
                self.losses = stats['losses']
                self.draws = stats['draws']
                return True
        except FileNotFoundError:
            return False


class TrainingThread(QThread):
    """
    ğŸƒâ€â™‚ï¸ Thread separatÄƒ pentru antrenament - nu blocheazÄƒ interfaÈ›a
    """
    progress_updated = pyqtSignal(int, dict)  # progres, statistici
    training_completed = pyqtSignal()

    def __init__(self, agent, episodes=1000):
        super().__init__()
        self.agent = agent
        self.episodes = episodes
        self.should_stop = False

    def run(self):
        """
        ğŸ¯ Antrenamentul propriu-zis - self-play
        """
        for episode in range(self.episodes):
            if self.should_stop:
                break

            # JoacÄƒ un joc complet Ã®mpotriva unui adversar random
            self.play_training_game()

            # ActualizeazÄƒ progresul la fiecare 100 de jocuri
            if episode % 100 == 0:
                stats = self.agent.get_statistics()
                self.progress_updated.emit(episode, stats)

        self.training_completed.emit()

    def play_training_game(self):
        """
        ğŸ® JoacÄƒ un joc de antrenament Ã®mpotriva unui adversar random
        """
        board = [''] * 9
        ai_turn = random.choice([True, False])  # Cine Ã®ncepe aleator

        while True:
            # VerificÄƒ dacÄƒ jocul s-a terminat
            winner = self.check_winner(board)
            if winner is not None:
                # RecompensÄƒ finalÄƒ
                if winner == 'O':  # AI-ul a cÃ¢È™tigat
                    self.agent.game_ended(1.0)
                elif winner == 'X':  # AI-ul a pierdut
                    self.agent.game_ended(-1.0)
                else:  # Egalitate
                    self.agent.game_ended(0.0)
                break

            # Egalitate (tabla plinÄƒ)
            if '' not in board:
                self.agent.game_ended(0.0)
                break

            if ai_turn:
                # RÃ¢ndul AI-ului
                action = self.agent.choose_action(board, training=True)
                if action is not None and board[action] == '':
                    board[action] = 'O'
                    self.agent.update_q_value(-0.01)  # MicÄƒ penalizare pentru cÄƒ jocul continuÄƒ
                else:
                    # Mutare invalidÄƒ - penalizare mare
                    self.agent.game_ended(-0.5)
                    break
            else:
                # RÃ¢ndul adversarului random
                valid_moves = [i for i, cell in enumerate(board) if cell == '']
                if valid_moves:
                    move = random.choice(valid_moves)
                    board[move] = 'X'

            ai_turn = not ai_turn

    def check_winner(self, board):
        """
        ğŸ† VerificÄƒ cÃ¢È™tigÄƒtorul
        """
        win_conditions = [
            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # rÃ¢nduri
            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # coloane
            [0, 4, 8], [2, 4, 6]              # diagonale
        ]

        for condition in win_conditions:
            if board[condition[0]] == board[condition[1]] == board[condition[2]] != '':
                return board[condition[0]]
        return None

    def stop_training(self):
        self.should_stop = True


class MLExplanationDialog(QDialog):
    """
    ğŸ“ Dialog educaÈ›ional pentru explicarea deciziilor ML vs reguli simple
    """

    def __init__(self, ml_agent, board_state, chosen_move, parent=None):
        super().__init__(parent)
        self.ml_agent = ml_agent
        self.board_state = board_state[:]
        self.chosen_move = chosen_move
        self.initUI()

    def initUI(self):
        self.setWindowTitle('ğŸ§  AI cu Machine Learning vs AI cu Reguli Simple')
        self.setGeometry(250, 150, 800, 700)
        self.setStyleSheet("""
            QDialog {
                background: qlineargradient(x1: 0, y1: 0, x2: 0, y2: 1,
                                          stop: 0 #f8f9fa, stop: 1 #e9ecef);
            }
            QLabel {
                color: #2c3e50;
                font-family: Arial;
            }
        """)

        layout = QVBoxLayout()

        # Titlu
        title = QLabel('ğŸ¤– ComparaÈ›ie: AI cu Reguli vs AI cu Machine Learning')
        title.setAlignment(Qt.AlignCenter)
        title.setStyleSheet("""
            font-size: 20px;
            font-weight: bold;
            color: #ffffff;
            background-color: #2c3e50;
            padding: 15px;
            border-radius: 8px;
            margin: 10px;
        """)
        layout.addWidget(title)

        # Tab widget pentru comparaÈ›ie
        tabs = QTabWidget()

        # Tab 1: AI cu reguli simple
        rules_tab = self.create_rules_explanation()
        tabs.addTab(rules_tab, "ğŸ”§ AI cu Reguli Simple")

        # Tab 2: AI cu ML
        ml_tab = self.create_ml_explanation()
        tabs.addTab(ml_tab, "ğŸ§  AI cu Machine Learning")

        # Tab 3: ComparaÈ›ia
        comparison_tab = self.create_comparison()
        tabs.addTab(comparison_tab, "âš–ï¸ ComparaÈ›ie")

        layout.addWidget(tabs)

        # Buton Ã®nchidere
        close_btn = QPushButton('ÃnÈ›eleg diferenÈ›a! ğŸ“')
        close_btn.setStyleSheet("""
            background-color: #3498db;
            color: white;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            font-size: 14px;
            font-weight: bold;
        """)
        close_btn.clicked.connect(self.accept)
        layout.addWidget(close_btn)

        self.setLayout(layout)

    def create_rules_explanation(self):
        widget = QWidget()
        layout = QVBoxLayout()

        # ExplicaÈ›ie reguli simple
        explanation = QLabel("""
ğŸ”§ AI-ul cu REGULI SIMPLE (din xo_game.py):

ğŸ“‹ ALGORITM FIX - 3 paÈ™i:
1. Verific dacÄƒ pot cÃ¢È™tiga â†’ cÃ¢È™tig
2. Verific dacÄƒ adversarul poate cÃ¢È™tiga â†’ blochez
3. Altfel â†’ aleg random

âœ… AVANTAJE:
â€¢ Simplu de Ã®nÈ›eles È™i implementat
â€¢ Predictibil È™i controlabil
â€¢ Nu are nevoie de antrenament
â€¢ FuncÈ›ioneazÄƒ imediat

âŒ DEZAVANTAJE:
â€¢ Nu Ã®nvaÈ›Äƒ nimic din experienÈ›Äƒ
â€¢ Nu dezvoltÄƒ strategii avansate
â€¢ Nu se adapteazÄƒ la stilul adversarului
â€¢ Limitat la aceste 3 reguli pentru totdeauna

ğŸ¤– CONCLUZIE:
Acest AI este ca un robot care executÄƒ aceleaÈ™i instrucÈ›iuni.
Nu poate deveni mai bun decÃ¢t programatorul sÄƒu.
        """)

        explanation.setStyleSheet("""
            font-size: 13px;
            background-color: #fff3e0;
            padding: 15px;
            border-radius: 8px;
            border-left: 5px solid #ff9800;
        """)
        explanation.setWordWrap(True)
        layout.addWidget(explanation)

        widget.setLayout(layout)
        return widget

    def create_ml_explanation(self):
        widget = QWidget()
        layout = QVBoxLayout()

        # Statistici AI
        stats = self.ml_agent.get_statistics()

        explanation = QLabel(f"""
ğŸ§  AI-ul cu MACHINE LEARNING (Q-Learning):

ğŸ“Š STATISTICI ACTUALE:
â€¢ Jocuri jucate: {stats['total']}
â€¢ Rata de cÃ¢È™tig: {stats['win_rate']:.1%}
â€¢ Q-Table entries: {len(self.ml_agent.q_table)}

ğŸ¯ ALGORITM ADAPTIV:
â€¢ ÃncearcÄƒ diferite mutÄƒri (explorare)
â€¢ ÃnvaÈ›Äƒ din rezultate (recompense/penalizÄƒri)
â€¢ ÃÈ™i construieÈ™te o "memorie" (Q-Table)
â€¢ Devine mai bun cu fiecare joc

âœ… AVANTAJE:
â€¢ ÃnvaÈ›Äƒ È™i se Ã®mbunÄƒtÄƒÈ›eÈ™te constant
â€¢ Poate descoperi strategii necunoscute
â€¢ Se adapteazÄƒ la stilul adversarului
â€¢ Poate deveni mai bun decÃ¢t programatorul

âŒ DEZAVANTAJE:
â€¢ Are nevoie de mult antrenament
â€¢ Deciziile nu sunt transparente
â€¢ Poate face greÈ™eli Ã®n timpul Ã®nvÄƒÈ›Äƒrii
â€¢ NecesitÄƒ resurse computaÈ›ionale

ğŸ¤– CONCLUZIE:
Acest AI este ca un elev care Ã®nvaÈ›Äƒ din experienÈ›Äƒ.
Poate deveni mai bun decÃ¢t ne-am imaginat!

ğŸ” ULTIMA DECIZIE: {self.ml_agent.decision_reason}
        """)

        explanation.setStyleSheet("""
            font-size: 13px;
            background-color: #e8f5e8;
            padding: 15px;
            border-radius: 8px;
            border-left: 5px solid #4caf50;
        """)
        explanation.setWordWrap(True)
        layout.addWidget(explanation)

        widget.setLayout(layout)
        return widget

    def create_comparison(self):
        widget = QWidget()
        layout = QVBoxLayout()

        comparison = QLabel("""
âš–ï¸ COMPARAÈšIA FUNDAMENTALÄ‚:

ğŸ—ï¸ CONSTRUIREA:
â€¢ Reguli Simple: Programatorul scrie reguli explicite
â€¢ Machine Learning: AI-ul Ã®È™i descoperÄƒ singur regulile

ğŸ§  "GÃ‚NDIREA":
â€¢ Reguli Simple: "Am aceastÄƒ situaÈ›ie â†’ fac aceastÄƒ acÈ›iune"
â€¢ Machine Learning: "Ãn situaÈ›ii similare, aceastÄƒ acÈ›iune mi-a adus succes"

ğŸ“ˆ EVOLUÈšIA:
â€¢ Reguli Simple: RÄƒmÃ¢ne la fel pentru totdeauna
â€¢ Machine Learning: Devine mai bun cu timpul

ğŸ” TRANSPARENÈšA:
â€¢ Reguli Simple: È˜tim exact de ce face fiecare mutare
â€¢ Machine Learning: E misterios, chiar È™i pentru creatori

ğŸŒ APLICAREA ÃN REALITATE:

ğŸ”§ Unde folosim AI cu REGULI:
â€¢ Sisteme de siguranÈ›Äƒ (avioane, maÈ™ini)
â€¢ Protocoale medicale
â€¢ Sisteme de control industrial

ğŸ§  Unde folosim MACHINE LEARNING:
â€¢ RecunoaÈ™terea vocii (Siri, Alexa)
â€¢ RecomandÄƒri (Netflix, YouTube)
â€¢ Traduceri automate
â€¢ MaÈ™ini autonome
â€¢ Diagnostic medical avansat

ğŸ’­ PARADOXUL AI-ULUI MODERN:
Cu cÃ¢t AI-ul devine mai puternic, cu atÃ¢t devine mai misterios!
ChatGPT È™i alte AI-uri moderne sunt atÃ¢t de complexe Ã®ncÃ¢t
nici creatorii lor nu Ã®nÈ›eleg complet cum funcÈ›ioneazÄƒ.
        """)

        comparison.setStyleSheet("""
            font-size: 12px;
            background-color: #f0f0f0;
            padding: 15px;
            border-radius: 8px;
            border-left: 5px solid #9b59b6;
        """)
        comparison.setWordWrap(True)
        layout.addWidget(comparison)

        widget.setLayout(layout)
        return widget


class TicTacToeAI(QWidget):
    """
    ğŸ® Jocul principal cu AI Machine Learning
    """

    def __init__(self):
        super().__init__()
        self.ml_agent = QLearningAgent()
        self.training_thread = None

        # ÃncarcÄƒ modelul antrenat dacÄƒ existÄƒ
        if self.ml_agent.load_model('xo_ai_model.pkl'):
            print("âœ… Model antrenat Ã®ncÄƒrcat cu succes!")
        else:
            print("â„¹ï¸ Nu s-a gÄƒsit model antrenat. Ãncepe cu Q-Table gol.")

        self.initUI()

    def initUI(self):
        self.setWindowTitle('ğŸ§  X È™i O - AI cu Machine Learning (Q-Learning)')
        self.setGeometry(50, 50, 900, 700)

        # Layout principal cu splitter
        main_layout = QHBoxLayout()
        splitter = QSplitter(Qt.Horizontal)

        # Partea stÃ¢ngÄƒ - jocul
        game_widget = self.create_game_panel()
        splitter.addWidget(game_widget)

        # Partea dreaptÄƒ - antrenament È™i statistici
        training_widget = self.create_training_panel()
        splitter.addWidget(training_widget)

        splitter.setSizes([500, 400])
        main_layout.addWidget(splitter)
        self.setLayout(main_layout)

        # IniÈ›ializeazÄƒ jocul
        self.reset_game()

    def create_game_panel(self):
        """
        ğŸ® Panelul cu jocul propriu-zis
        """
        widget = QWidget()
        layout = QVBoxLayout()

        # Titlu
        title = QLabel('ğŸ¯ JoacÄƒ Ã®mpotriva AI-ului cu Machine Learning!')
        title.setAlignment(Qt.AlignCenter)
        title.setStyleSheet("font-size: 18px; font-weight: bold; color: #2c3e50; margin: 10px;")
        layout.addWidget(title)

        # Status
        self.status_label = QLabel('RÃ¢ndul tÄƒu (X)')
        self.status_label.setAlignment(Qt.AlignCenter)
        self.status_label.setStyleSheet("""
            font-size: 16px;
            font-weight: bold;
            background-color: #3498db;
            color: white;
            padding: 10px;
            border-radius: 5px;
        """)
        layout.addWidget(self.status_label)

        # AI thinking
        self.thinking_label = QLabel('')
        self.thinking_label.setAlignment(Qt.AlignCenter)
        self.thinking_label.setStyleSheet("""
            font-size: 14px;
            background-color: #e67e22;
            color: white;
            padding: 8px;
            border-radius: 5px;
            font-weight: bold;
        """)
        self.thinking_label.hide()
        layout.addWidget(self.thinking_label)

        # Grid de joc
        grid_layout = QVBoxLayout()
        self.buttons = []
        for i in range(3):
            row_layout = QHBoxLayout()
            for j in range(3):
                button = QPushButton('')
                button.setFixedSize(80, 80)
                button.setStyleSheet("""
                    QPushButton {
                        font-size: 24px;
                        font-weight: bold;
                        border: 2px solid #34495e;
                        border-radius: 8px;
                        background-color: #ecf0f1;
                    }
                    QPushButton:hover {
                        background-color: #bdc3c7;
                    }
                """)
                index = i * 3 + j
                button.clicked.connect(lambda _, idx=index: self.on_button_click(idx))
                self.buttons.append(button)
                row_layout.addWidget(button)
            grid_layout.addLayout(row_layout)
        layout.addLayout(grid_layout)

        # Butoane control
        control_layout = QHBoxLayout()

        self.new_game_btn = QPushButton('ğŸ”„ Joc Nou')
        self.new_game_btn.clicked.connect(self.reset_game)

        self.explain_btn = QPushButton('ğŸ§  ExplicÄƒ decizia AI')
        self.explain_btn.clicked.connect(self.explain_ai_decision)
        self.explain_btn.setEnabled(False)

        control_layout.addWidget(self.new_game_btn)
        control_layout.addWidget(self.explain_btn)
        layout.addLayout(control_layout)

        widget.setLayout(layout)
        return widget

    def create_training_panel(self):
        """
        ğŸƒâ€â™‚ï¸ Panelul pentru antrenament È™i monitorizare
        """
        widget = QWidget()
        layout = QVBoxLayout()

        # Titlu antrenament
        training_title = QLabel('ğŸ“ Antrenament Machine Learning')
        training_title.setAlignment(Qt.AlignCenter)
        training_title.setStyleSheet("font-size: 16px; font-weight: bold; color: #2c3e50;")
        layout.addWidget(training_title)

        # Statistici actuale
        self.stats_label = QLabel(self.get_stats_text())
        self.stats_label.setStyleSheet("""
            background-color: #f8f9fa;
            padding: 10px;
            border-radius: 5px;
            border: 1px solid #dee2e6;
        """)
        layout.addWidget(self.stats_label)

        # Progress bar
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)

        # Butoane antrenament
        training_layout = QHBoxLayout()

        self.train_btn = QPushButton('ğŸƒâ€â™‚ï¸ AntreneazÄƒ (1000 jocuri)')
        self.train_btn.clicked.connect(self.start_training)

        self.stop_btn = QPushButton('â¹ï¸ Stop')
        self.stop_btn.clicked.connect(self.stop_training)
        self.stop_btn.setEnabled(False)

        training_layout.addWidget(self.train_btn)
        training_layout.addWidget(self.stop_btn)
        layout.addLayout(training_layout)

        # Salvare/ÃncÄƒrcare model
        model_layout = QHBoxLayout()

        save_btn = QPushButton('ğŸ’¾ SalveazÄƒ AI antrenat')
        save_btn.clicked.connect(self.save_model)

        load_btn = QPushButton('ğŸ“ ÃncarcÄƒ AI antrenat')
        load_btn.clicked.connect(self.load_model)

        model_layout.addWidget(save_btn)
        model_layout.addWidget(load_btn)
        layout.addLayout(model_layout)

        # ExplicaÈ›ii educaÈ›ionale
        education_text = QLabel("""
ğŸ¯ CE SE ÃNTÃ‚MPLÄ‚ ÃN ANTRENAMENT:

1. AI-ul joacÄƒ mii de jocuri Ã®mpotriva unui adversar random
2. Pentru fiecare mutare, primeÈ™te recompense:
   â€¢ +1 pentru cÃ¢È™tig
   â€¢ -1 pentru pierdere
   â€¢ 0 pentru egalitate
   â€¢ -0.01 pentru continuarea jocului
3. ConstruieÈ™te o "memorie" (Q-Table) cu ce sÄƒ facÄƒ Ã®n fiecare situaÈ›ie
4. BalanseazÄƒ explorarea (mutÄƒri noi) cu exploatarea (mutÄƒri cunoscute ca bune)

ğŸ’¡ Cu cÃ¢t joacÄƒ mai mult, cu atÃ¢t devine mai inteligent!
        """)
        education_text.setStyleSheet("""
            background-color: #e8f5e8;
            padding: 10px;
            border-radius: 5px;
            font-size: 11px;
            border-left: 4px solid #4caf50;
        """)
        education_text.setWordWrap(True)
        layout.addWidget(education_text)

        layout.addStretch()
        widget.setLayout(layout)
        return widget

    def get_stats_text(self):
        """
        ğŸ“Š Text cu statisticile curente
        """
        stats = self.ml_agent.get_statistics()
        return f"""
ğŸ“Š STATISTICI AI:
â€¢ Jocuri jucate: {stats['total']}
â€¢ Victorii: {stats['wins']} ({stats['win_rate']:.1%})
â€¢ ÃnfrÃ¢ngeri: {stats['losses']} ({stats['loss_rate']:.1%})
â€¢ EgalitÄƒÈ›i: {stats['draws']} ({stats['draw_rate']:.1%})
â€¢ IntrÄƒri Ã®n Q-Table: {len(self.ml_agent.q_table)}
        """

    def reset_game(self):
        """
        ğŸ”„ ReseteazÄƒ jocul
        """
        self.board = [''] * 9
        self.player_turn = True
        self.game_over = False
        self.last_ai_move = None

        for button in self.buttons:
            button.setText('')
            button.setEnabled(True)
            button.setStyleSheet("""
                QPushButton {
                    font-size: 24px;
                    font-weight: bold;
                    border: 2px solid #34495e;
                    border-radius: 8px;
                    background-color: #ecf0f1;
                }
                QPushButton:hover {
                    background-color: #bdc3c7;
                }
            """)

        self.status_label.setText('RÃ¢ndul tÄƒu (X)')
        self.thinking_label.hide()
        self.explain_btn.setEnabled(False)

    def on_button_click(self, index):
        """
        ğŸ–±ï¸ Click pe butonul din grid
        """
        if not self.player_turn or self.game_over or self.board[index] != '':
            return

        # Mutarea jucÄƒtorului
        self.board[index] = 'X'
        self.buttons[index].setText('X')
        self.buttons[index].setStyleSheet("""
            QPushButton {
                font-size: 24px;
                font-weight: bold;
                border: 2px solid #34495e;
                border-radius: 8px;
                background-color: #3498db;
                color: white;
            }
        """)

        # VerificÄƒ sfÃ¢rÈ™itul jocului
        if self.check_game_end():
            return

        # RÃ¢ndul AI-ului
        self.player_turn = False
        self.status_label.setText('ğŸ¤– AI-ul se gÃ¢ndeÈ™te...')
        self.thinking_label.setText('ğŸ§  Analizez Q-Table-ul...')
        self.thinking_label.show()

        # SimuleazÄƒ "gÃ¢ndirea" AI-ului
        QTimer.singleShot(1500, self.ai_move)

    def ai_move(self):
        """
        ğŸ¤– Mutarea AI-ului
        """
        action = self.ml_agent.choose_action(self.board, training=False)

        if action is not None:
            self.board[action] = 'O'
            self.buttons[action].setText('O')
            self.buttons[action].setStyleSheet("""
                QPushButton {
                    font-size: 24px;
                    font-weight: bold;
                    border: 2px solid #34495e;
                    border-radius: 8px;
                    background-color: #e74c3c;
                    color: white;
                }
            """)

            self.last_ai_move = action
            self.explain_btn.setEnabled(True)

            # AfiÈ™eazÄƒ decizia AI-ului
            self.thinking_label.setText(self.ml_agent.decision_reason)
            QTimer.singleShot(3000, self.thinking_label.hide)

        if not self.check_game_end():
            self.player_turn = True
            self.status_label.setText('RÃ¢ndul tÄƒu (X)')

    def check_game_end(self):
        """
        ğŸ VerificÄƒ sfÃ¢rÈ™itul jocului
        """
        winner = self.check_winner()

        if winner:
            self.game_over = True
            self.thinking_label.hide()

            if winner == 'X':
                self.status_label.setText('ğŸ‰ Ai cÃ¢È™tigat!')
                self.ml_agent.game_ended(-1.0)  # AI-ul a pierdut
            elif winner == 'O':
                self.status_label.setText('ğŸ¤– AI-ul a cÃ¢È™tigat!')
                self.ml_agent.game_ended(1.0)   # AI-ul a cÃ¢È™tigat

            for button in self.buttons:
                button.setEnabled(False)

            # ActualizeazÄƒ statisticile
            self.stats_label.setText(self.get_stats_text())
            return True

        elif '' not in self.board:
            # Egalitate
            self.game_over = True
            self.status_label.setText('ğŸ¤ Egalitate!')
            self.ml_agent.game_ended(0.0)
            self.thinking_label.hide()

            for button in self.buttons:
                button.setEnabled(False)

            self.stats_label.setText(self.get_stats_text())
            return True

        return False

    def check_winner(self):
        """
        ğŸ† VerificÄƒ cÃ¢È™tigÄƒtorul
        """
        win_conditions = [
            [0, 1, 2], [3, 4, 5], [6, 7, 8],  # rÃ¢nduri
            [0, 3, 6], [1, 4, 7], [2, 5, 8],  # coloane
            [0, 4, 8], [2, 4, 6]              # diagonale
        ]

        for condition in win_conditions:
            if (self.board[condition[0]] == self.board[condition[1]] ==
                self.board[condition[2]] != ''):
                return self.board[condition[0]]
        return None

    def explain_ai_decision(self):
        """
        ğŸ§  ExplicÄƒ decizia AI-ului
        """
        if self.last_ai_move is not None:
            dialog = MLExplanationDialog(self.ml_agent, self.board, self.last_ai_move, self)
            dialog.exec_()

    def start_training(self):
        """
        ğŸƒâ€â™‚ï¸ Ãncepe antrenamentul
        """
        self.training_thread = TrainingThread(self.ml_agent, episodes=1000)
        self.training_thread.progress_updated.connect(self.update_training_progress)
        self.training_thread.training_completed.connect(self.training_finished)

        self.train_btn.setEnabled(False)
        self.stop_btn.setEnabled(True)
        self.progress_bar.setVisible(True)
        self.progress_bar.setMaximum(1000)

        self.training_thread.start()

    def update_training_progress(self, episode, stats):
        """
        ğŸ“Š ActualizeazÄƒ progresul antrenamentului
        """
        self.progress_bar.setValue(episode)
        self.stats_label.setText(self.get_stats_text())

    def training_finished(self):
        """
        ğŸ Antrenamentul s-a terminat
        """
        self.train_btn.setEnabled(True)
        self.stop_btn.setEnabled(False)
        self.progress_bar.setVisible(False)
        self.stats_label.setText(self.get_stats_text())

        # SalveazÄƒ automat modelul
        self.save_model()

    def stop_training(self):
        """
        â¹ï¸ OpreÈ™te antrenamentul
        """
        if self.training_thread:
            self.training_thread.stop_training()

    def save_model(self):
        """
        ğŸ’¾ SalveazÄƒ modelul antrenat
        """
        self.ml_agent.save_model('xo_ai_model.pkl')
        self.status_label.setText('ğŸ’¾ Model salvat cu succes!')
        QTimer.singleShot(2000, lambda: self.status_label.setText('RÃ¢ndul tÄƒu (X)' if self.player_turn else 'ğŸ¤– AI-ul se gÃ¢ndeÈ™te...'))

    def load_model(self):
        """
        ğŸ“ ÃncarcÄƒ un model antrenat
        """
        if self.ml_agent.load_model('xo_ai_model.pkl'):
            self.stats_label.setText(self.get_stats_text())
            self.status_label.setText('ğŸ“ Model Ã®ncÄƒrcat cu succes!')
            QTimer.singleShot(2000, lambda: self.status_label.setText('RÃ¢ndul tÄƒu (X)' if self.player_turn else 'ğŸ¤– AI-ul se gÃ¢ndeÈ™te...'))
        else:
            self.status_label.setText('âš ï¸ Nu s-a gÄƒsit model salvat!')
            QTimer.singleShot(2000, lambda: self.status_label.setText('RÃ¢ndul tÄƒu (X)' if self.player_turn else 'ğŸ¤– AI-ul se gÃ¢ndeÈ™te...'))


if __name__ == '__main__':
    print("""
    ğŸ§  X È™i O cu Machine Learning - Pornire aplicaÈ›ie
    ================================================

    AceastÄƒ aplicaÈ›ie demonstreazÄƒ diferenÈ›a dintre:
    1. AI cu reguli simple (din xo_game.py)
    2. AI cu Machine Learning (Q-Learning)

    ğŸ’¡ Sugestii:
    1. JoacÄƒ cÃ¢teva jocuri pentru a vedea cum se comportÄƒ AI-ul iniÈ›ial
    2. AntreneazÄƒ AI-ul (butonul "AntreneazÄƒ")
    3. JoacÄƒ din nou È™i observÄƒ Ã®mbunÄƒtÄƒÈ›irea
    4. FoloseÈ™te butonul "ExplicÄƒ decizia" pentru a Ã®nÈ›elege diferenÈ›ele

    ğŸ¯ Scopul educaÈ›ional: SÄƒ Ã®nÈ›elegi diferenÈ›a dintre programarea
    tradiÈ›ionalÄƒ (reguli explicite) È™i Machine Learning (Ã®nvÄƒÈ›are din experienÈ›Äƒ)
    """)

    app = QApplication(sys.argv)
    game = TicTacToeAI()
    game.show()
    sys.exit(app.exec_())