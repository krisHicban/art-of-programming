from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

# Presupunem cÄƒ avem X_train, X_test, y_train, y_test (NON-scaled!)

# ========================================
# PIPELINE 1: SVM CU STANDARD SCALER
# ========================================

print("=" * 60)
print("ðŸ”µ PIPELINE 1: StandardScaler â†’ SVM")
print("=" * 60)

# CreeazÄƒ pipeline-ul
svm_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42))
])

# AntreneazÄƒ pipeline-ul (scalare + antrenare Ã®ntr-un singur pas!)
svm_pipeline.fit(X_train, y_train)

# PredicÈ›ie (scalare + predicÈ›ie automat!)
svm_pred = svm_pipeline.predict(X_test)
svm_accuracy = accuracy_score(y_test, svm_pred)

print(f"\nâœ… AcurateÈ›e SVM Pipeline: {svm_accuracy:.4f}")
print(f"\nðŸ“‹ PaÈ™i Ã®n pipeline: {[name for name, _ in svm_pipeline.steps]}")

# ========================================
# PIPELINE 2: RANDOM FOREST
# ========================================

print("\n" + "=" * 60)
print("ðŸŸ¢ PIPELINE 2: StandardScaler â†’ Random Forest")
print("=" * 60)

rf_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10,
                                         random_state=42))
])

rf_pipeline.fit(X_train, y_train)
rf_pred = rf_pipeline.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_pred)

print(f"\nâœ… AcurateÈ›e Random Forest Pipeline: {rf_accuracy:.4f}")

# ========================================
# PIPELINE 3: KNN
# ========================================

print("\n" + "=" * 60)
print("ðŸŸ£ PIPELINE 3: StandardScaler â†’ KNN")
print("=" * 60)

knn_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', KNeighborsClassifier(n_neighbors=5))
])

knn_pipeline.fit(X_train, y_train)
knn_pred = knn_pipeline.predict(X_test)
knn_accuracy = accuracy_score(y_test, knn_pred)

print(f"\nâœ… AcurateÈ›e KNN Pipeline: {knn_accuracy:.4f}")

# ========================================
# BENEFICIILE PIPELINE-URILOR
# ========================================

print("\n" + "=" * 60)
print("ðŸŽ¯ BENEFICIILE PIPELINE-URILOR")
print("=" * 60)

print("""
1. ðŸ”’ ZERO DATA LEAKAGE:
   - Scaler Ã®nvaÈ›Äƒ DOAR din train
   - Test nu influenÈ›eazÄƒ niciodatÄƒ transformÄƒrile

2. ðŸ“ COD MAI CURAT:
   - fit() È™i predict() Ã®ntr-un singur apel
   - Nu mai ai nevoie de variabile separate pentru scaled data

3. ðŸ”„ REPRODUCIBILITATE:
   - ÃŽntregul workflow Ã®ntr-un singur obiect
   - PoÈ›i salva pipeline-ul È™i Ã®l foloseÈ™ti identic mai tÃ¢rziu

4. ðŸš€ DEPLOYMENT MAI UÈ˜OR:
   - Un singur obiect de salvat: pickle.dump(pipeline, file)
   - ÃŽn producÈ›ie: pickle.load() â†’ pipeline.predict()

5. ðŸ› ï¸ COMPATIBIL CU GRIDSERCHCV:
   - PoÈ›i optimiza hyperparametri pentru TOÈšI paÈ™ii
   - Cross-validation corectÄƒ automat
""")

# ========================================
# SALVARE È˜I ÃŽNCÄ‚RCARE PIPELINE
# ========================================

print("\n" + "=" * 60)
print("ðŸ’¾ SALVARE È˜I ÃŽNCÄ‚RCARE PIPELINE")
print("=" * 60)

import joblib

# SalveazÄƒ cel mai bun pipeline
best_pipeline = svm_pipeline
joblib.dump(best_pipeline, 'breast_cancer_classifier_pipeline.pkl')
print("\nâœ… Pipeline salvat: breast_cancer_classifier_pipeline.pkl")

# ÃŽncarcÄƒ pipeline-ul
loaded_pipeline = joblib.load('breast_cancer_classifier_pipeline.pkl')
print("âœ… Pipeline Ã®ncÄƒrcat cu succes!")

# TesteazÄƒ cÄƒ funcÈ›ioneazÄƒ identic
loaded_pred = loaded_pipeline.predict(X_test)
loaded_accuracy = accuracy_score(y_test, loaded_pred)
print(f"\nðŸ” AcurateÈ›e pipeline Ã®ncÄƒrcat: {loaded_accuracy:.4f}")
print(f"âœ… Match cu original: {loaded_accuracy == svm_accuracy}")

# ========================================
# PREDICÈšIE PE DATE NOI (SIMULARE)
# ========================================

print("\n" + "=" * 60)
print("ðŸ¥ PREDICÈšIE PE DATE NOI - SIMULARE SPITAL")
print("=" * 60)

# SimuleazÄƒ un pacient nou (30 features)
new_patient = np.array([cancer_data.data[0]])  # folosim prima sample ca exemplu

print("\nðŸ“‹ Date pacient nou (primele 5 features):")
print(new_patient[0][:5])

# PredicÈ›ie cu pipeline (scalare automatÄƒ!)
prediction = loaded_pipeline.predict(new_patient)
prediction_proba = loaded_pipeline.predict_proba(new_patient)

diagnosis = "MalignÄƒ ðŸ”´" if prediction[0] == 0 else "BenignÄƒ ðŸŸ¢"
confidence = max(prediction_proba[0]) * 100

print(f"\nðŸ¥ DIAGNOSTIC: {diagnosis}")
print(f"ðŸ“Š Confidence: {confidence:.2f}%")
print(f"\nðŸ“ˆ ProbabilitÄƒÈ›i:")
print(f"   - MalignÄƒ: {prediction_proba[0][0] * 100:.2f}%")
print(f"   - BenignÄƒ: {prediction_proba[0][1] * 100:.2f}%")

if prediction[0] == 0:
    print("\nâš ï¸ RECOMANDARE: Consultare oncolog urgentÄƒ + biopsie suplimentarÄƒ")
else:
    print("\nâœ… RECOMANDARE: Control de rutinÄƒ peste 6 luni")

# ========================================
# CROSS-VALIDATION CU PIPELINE
# ========================================

print("\n" + "=" * 60)
print("ðŸ”„ CROSS-VALIDATION CU PIPELINE (5-Fold)")
print("=" * 60)

# Cross-validation pe SVM pipeline
cv_scores = cross_val_score(svm_pipeline, X_train, y_train, cv=5, scoring='accuracy')

print(f"\nðŸ“Š Scoruri pentru fiecare fold:")
for i, score in enumerate(cv_scores, 1):
    print(f"   Fold {i}: {score:.4f}")

print(f"\nâœ… Media: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
print(f"\nðŸ’¡ Interpretare:")
print(f"   - Modelul are ~{cv_scores.mean() * 100:.2f}% acurateÈ›e pe date nevÄƒzute")
print(f"   - VariaÈ›ie micÄƒ ({cv_scores.std():.4f}) = model stabil!")

print("""
\nðŸŽ“ DE CE CROSS-VALIDATION?
   - Un singur test set poate fi norocos/nenorocos
   - CV testeazÄƒ pe 5 pÄƒrÈ›i diferite â†’ estimare mai realistÄƒ
   - DetecteazÄƒ overfitting: dacÄƒ train score >> CV score
""")

