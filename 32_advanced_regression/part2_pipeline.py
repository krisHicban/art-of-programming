import pandas as pd
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

# ÃncarcÄƒ dataset-ul
df = pd.read_csv('apartamente_bucuresti.csv')

# ========================================
# PARTEA 1: SEPARAREA FEATURES & TARGET
# ========================================

# Features (X) È™i Target (y)
X = df.drop('pret', axis=1)
y = df['pret']

print("ğŸ“Š STRUCTURA DATELOR:")
print(f"Features (X): {X.shape}")
print(f"Target (y): {y.shape}")
print(f"\nColoane Ã®n X:\n{X.columns.tolist()}")

# ========================================
# PARTEA 2: IDENTIFICAREA TIPURILOR
# ========================================

# IdentificÄƒ automat coloanele numerice È™i categorice
numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

# Future-proof: include both 'object' and 'string' dtypes
categorical_features = X.select_dtypes(include=['object', 'string']).columns.tolist()

print(f"\nğŸ”¢ NUMERICAL FEATURES ({len(numerical_features)}):")
print(numerical_features)

print(f"\nğŸ·ï¸ CATEGORICAL FEATURES ({len(categorical_features)}):")
print(categorical_features)

# ========================================
# PARTEA 3: CREAREA TRANSFORMERS
# ========================================

# Transformer pentru features numerice
numerical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),    # CompleteazÄƒ cu media
    ('scaler', StandardScaler())                     # NormalizeazÄƒ
])

# Transformer pentru features categorice
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),  # CompleteazÄƒ cu cel mai frecvent
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Encodare
])

print("\nâœ… TRANSFORMERS CREAÈšI:")
print("  1. Numerical: SimpleImputer(mean) â†’ StandardScaler")
print("  2. Categorical: SimpleImputer(most_frequent) â†’ OneHotEncoder")

# ========================================
# PARTEA 4: COLUMN TRANSFORMER
# ========================================

# CombinÄƒm transformers-ii folosind ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ],
    remainder='drop'  # Drop orice altÄƒ coloanÄƒ nespecificatÄƒ
)

print("\nğŸ”§ COLUMN TRANSFORMER CREAT!")
print(f"  - Va procesa {len(numerical_features)} numerical features")
print(f"  - Va procesa {len(categorical_features)} categorical features")

# ========================================
# PARTEA 5: TRAIN-TEST SPLIT
# ========================================

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nğŸ“¦ TRAIN-TEST SPLIT:")
print(f"Training set: {X_train.shape[0]} apartamente ({X_train.shape[0]/len(X)*100:.1f}%)")
print(f"Test set: {X_test.shape[0]} apartamente ({X_test.shape[0]/len(X)*100:.1f}%)")

# ========================================
# PARTEA 6: FIT & TRANSFORM
# ========================================

# Fit preprocessor pe training data
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

print(f"\nğŸ¯ PREPROCESSING COMPLET:")
print(f"  Ãnainte: {X_train.shape} â†’ DupÄƒ: {X_train_processed.shape}")
print(f"  Features create: {X_train_processed.shape[1]}")

# ========================================
# PARTEA 7: ÃNÈšELEGEREA OUTPUT-ULUI
# ========================================

# ObÈ›ine numele features dupÄƒ OneHotEncoding
feature_names = []

# Numerical features (same names)
feature_names.extend(numerical_features)

# Categorical features (get encoded names from OneHotEncoder)
cat_encoder = preprocessor.named_transformers_['cat']['onehot']
cat_feature_names = cat_encoder.get_feature_names_out(categorical_features)
feature_names.extend(cat_feature_names)

print(f"\nğŸ“‹ TOATE FEATURES DUPÄ‚ PREPROCESSING ({len(feature_names)}):")
for i, name in enumerate(feature_names[:20], 1):  # AfiÈ™Äƒm primele 20
    print(f"  {i}. {name}")
if len(feature_names) > 20:
    print(f"  ... È™i {len(feature_names) - 20} mai multe")

# Exemplu: Cum aratÄƒ o singurÄƒ observaÈ›ie dupÄƒ preprocessing
print(f"\nğŸ” EXEMPLU - PRIMA OBSERVAÈšIE TRAIN:")
print(f"Ãnainte (primele 5 features):\n{X_train.iloc[0][:5]}")
print(f"\nDupÄƒ preprocessing (primele 10 values):\n{X_train_processed[0][:10]}")

# ========================================
# CE SE ÃNTÃ‚MPLÄ‚ ÃN SPATE?
# ========================================

print("""
\nğŸ’¡ CE FACE COLUMN TRANSFORMER:

1. PENTRU NUMERICAL FEATURES:
   - suprafata: 75 mp (cu missing) â†’ impute cu mean â†’ scale cu StandardScaler â†’ 0.42
   - etaj: 3 â†’ scale â†’ -0.15
   - numar_camere: 2 â†’ scale â†’ 0.38

2. PENTRU CATEGORICAL FEATURES:
   - zona: "Floreasca" â†’ OneHotEncoder â†’ [0,0,0,1,0,0,0,0]
   - balcon: "da" â†’ OneHotEncoder â†’ [1,0]
   - parcare: "nu" â†’ OneHotEncoder â†’ [0,1]

3. CONCATENEAZÄ‚ TOT:
   [0.42, -0.15, 0.38, ..., 0,0,0,1,0,0,0,0, 1,0, 0,1]

4. REZULTAT:
   - Vector numeric complet
   - Gata pentru ML model
   - ZERO data leakage (test foloseÈ™te parametrii din train!)

ğŸš€ URMÄ‚TORUL PAS: Antrenarea modelelor!
""")