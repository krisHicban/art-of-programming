import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

# ==========================================
# APPLICATION 1: PNEUMONIA DETECTION (Health)
# ==========================================

def build_pneumonia_classifier():
    """
    HEALTH APPLICATION: Detect pneumonia from chest X-rays

    Dataset: Chest X-rays (224x224 grayscale)
    Classes: Normal vs Pneumonia

    Why CNN over traditional CV?
    - OpenCV can detect edges, but not disease patterns
    - Pneumonia has subtle opacity patterns
    - CNN learns hierarchical features automatically:
      Layer 1: Edges, textures
      Layer 2: Lung shapes, vessel patterns
      Layer 3: Opacity distributions
      Layer 4: Disease signatures

    This architecture is used in real FDA-approved medical AI.
    """

    print("=" * 70)
    print("APPLICATION 1: PNEUMONIA DETECTION FROM CHEST X-RAYS")
    print("=" * 70)
    print()

    model = keras.Sequential([
        # Input: 224x224x1 (grayscale X-ray)
        layers.Input(shape=(224, 224, 1)),

        # Block 1: Feature extraction at original resolution
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_1'),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1_2'),
        layers.MaxPooling2D((2, 2), name='pool1'),  # 112x112x32
        layers.BatchNormalization(name='bn1'),

        # Block 2: Mid-level features (lung structures)
        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_1'),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2_2'),
        layers.MaxPooling2D((2, 2), name='pool2'),  # 56x56x64
        layers.BatchNormalization(name='bn2'),

        # Block 3: High-level features (opacity patterns)
        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_1'),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='conv3_2'),
        layers.MaxPooling2D((2, 2), name='pool3'),  # 28x28x128
        layers.BatchNormalization(name='bn3'),

        # Block 4: Disease-specific patterns
        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_1'),
        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='conv4_2'),
        layers.GlobalAveragePooling2D(name='gap'),  # Spatial dimensions ‚Üí single vector

        # Classification head
        layers.Dense(128, activation='relu', name='fc1'),
        layers.Dropout(0.5, name='dropout'),
        layers.Dense(1, activation='sigmoid', name='output')  # Binary: Normal/Pneumonia
    ])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.0001),
        loss='binary_crossentropy',
        metrics=['accuracy', keras.metrics.AUC(name='auc')]
    )

    print("üè• PNEUMONIA DETECTION CNN ARCHITECTURE:")
    print()
    model.summary()

    print()
    print("üìä CLINICAL VALIDATION METRICS:")
    print("   Accuracy: How often predictions are correct")
    print("   AUC: Area Under ROC Curve (discrimination ability)")
    print("   Sensitivity (Recall): % of pneumonia cases detected")
    print("   Specificity: % of healthy cases correctly identified")
    print()
    print("‚ö†Ô∏è  CRITICAL: In medical AI, FALSE NEGATIVES are dangerous")
    print("   (Missing a pneumonia case is worse than a false alarm)")
    print("   So we optimize for HIGH SENSITIVITY (>95%)")
    print()

    return model

pneumonia_model = build_pneumonia_classifier()

# ==========================================
# APPLICATION 2: DIABETIC RETINOPATHY (Health)
# ==========================================

def build_retinopathy_classifier():
    """
    HEALTH APPLICATION: Detect diabetic retinopathy from retinal images

    Dataset: Retinal fundus images (512x512 RGB)
    Classes: 5 severity levels (No DR, Mild, Moderate, Severe, Proliferative)

    Why this matters:
    - Diabetic retinopathy is the leading cause of preventable blindness
    - Early detection can save vision
    - Manual screening is time-consuming and expensive
    - CNN can screen thousands of patients per day

    Real impact: Google's model deployed in India, Thailand
    Screens rural patients with 90%+ accuracy
    """

    print()
    print("=" * 70)
    print("APPLICATION 2: DIABETIC RETINOPATHY DETECTION")
    print("=" * 70)
    print()

    model = keras.Sequential([
        # Input: 512x512x3 (RGB retinal image)
        layers.Input(shape=(512, 512, 3)),

        # Initial downsampling to reduce computation
        layers.Conv2D(32, (7, 7), strides=2, activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),  # 128x128x32

        # Feature extraction blocks
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),  # 64x64x64
        layers.BatchNormalization(),

        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),  # 32x32x128
        layers.BatchNormalization(),

        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
        layers.GlobalAveragePooling2D(),

        # Multi-class classification (5 severity levels)
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(5, activation='softmax')  # 5 classes
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    print("üëÅÔ∏è RETINOPATHY DETECTION CNN:")
    print()
    model.summary()

    print()
    print("üåç REAL-WORLD IMPACT:")
    print("   ‚Ä¢ Deployed in 20+ countries")
    print("   ‚Ä¢ Screens 100,000+ patients annually")
    print("   ‚Ä¢ Reduces blindness by early intervention")
    print("   ‚Ä¢ Cost: \$10/screening vs \$100+ for specialist")
    print()

    return model

retinopathy_model = build_retinopathy_classifier()

# ==========================================
# APPLICATION 3: SATELLITE IMAGERY - AIR QUALITY MONITORING
# ==========================================

def build_air_quality_classifier():
    """
    ENVIRONMENTAL APPLICATION: Air Quality Assessment from Satellite Images

    Dataset: Satellite images (256x256 RGB) from Sentinel-2, Landsat-8
    Task: Classify air quality levels from visual haze, pollution patterns

    Features CNNs learn:
    - Layer 1: Cloud patterns, atmospheric clarity
    - Layer 2: Haze distribution, visibility ranges
    - Layer 3: Industrial emission plumes
    - Layer 4: Urban pollution patterns, smog coverage

    Why this matters:
    - Real-time air quality monitoring without ground sensors
    - Coverage of remote/underserved areas
    - Early warning for pollution events
    - Track pollution sources from space

    Real applications:
    - NASA uses CNNs to track global pollution from satellite data
    - European Space Agency monitors industrial emissions
    - Cities use this for pollution source attribution
    - Health agencies predict pollution-related hospital admissions
    """

    print()
    print("=" * 70)
    print("APPLICATION 3: SATELLITE-BASED AIR QUALITY MONITORING")
    print("=" * 70)
    print()

    model = keras.Sequential([
        # Input: 256x256x3 (RGB satellite image)
        layers.Input(shape=(256, 256, 3)),

        # Block 1: Atmospheric clarity detection
        layers.Conv2D(32, (5, 5), activation='relu', padding='same', name='atmos_detect_1'),
        layers.Conv2D(32, (5, 5), activation='relu', padding='same', name='atmos_detect_2'),
        layers.MaxPooling2D((2, 2)),  # 128x128x32
        layers.BatchNormalization(),

        # Block 2: Haze and visibility patterns
        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='haze_patterns_1'),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='haze_patterns_2'),
        layers.MaxPooling2D((2, 2)),  # 64x64x64
        layers.BatchNormalization(),

        # Block 3: Pollution plume detection
        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='plume_detect_1'),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='plume_detect_2'),
        layers.MaxPooling2D((2, 2)),  # 32x32x128
        layers.BatchNormalization(),

        # Block 4: Urban smog patterns
        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='smog_patterns_1'),
        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='smog_patterns_2'),
        layers.GlobalAveragePooling2D(),

        # Classification: Air Quality Index levels
        # Good (0-50), Moderate (51-100), Unhealthy for Sensitive (101-150),
        # Unhealthy (151-200), Very Unhealthy (201-300), Hazardous (300+)
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.4),
        layers.Dense(6, activation='softmax', name='aqi_classification')  # 6 AQI categories
    ])

    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.0001),
        loss='categorical_crossentropy',
        metrics=['accuracy', 'top_k_categorical_accuracy']
    )

    print("üåç AIR QUALITY MONITORING CNN:")
    print()
    model.summary()

    print()
    print("üå¨Ô∏è WHAT THE CNN LEARNS TO DETECT:")
    print()
    print("Layer 1 (Low-level features):")
    print("   ‚Ä¢ Cloud edges and atmospheric clarity")
    print("   ‚Ä¢ Contrast differences (haze reduces contrast)")
    print("   ‚Ä¢ Color shifts (pollution causes brownish tint)")
    print()
    print("Layer 2 (Mid-level patterns):")
    print("   ‚Ä¢ Haze distribution patterns")
    print("   ‚Ä¢ Visibility gradients across the image")
    print("   ‚Ä¢ Atmospheric opacity measurements")
    print()
    print("Layer 3 (High-level structures):")
    print("   ‚Ä¢ Industrial emission plumes")
    print("   ‚Ä¢ Point source pollution (factories, power plants)")
    print("   ‚Ä¢ Traffic-related pollution corridors")
    print()
    print("Layer 4 (Semantic understanding):")
    print("   ‚Ä¢ Urban smog coverage area")
    print("   ‚Ä¢ Pollution severity indicators")
    print("   ‚Ä¢ Temporal pollution patterns (morning/evening peaks)")
    print()
    print("üéØ REAL-WORLD APPLICATIONS:")
    print()
    print("1. Public Health Alerts:")
    print("   ‚Ä¢ Predict AQI 24-48 hours in advance")
    print("   ‚Ä¢ Issue warnings for sensitive populations")
    print("   ‚Ä¢ Track pollution episodes in real-time")
    print()
    print("2. Source Attribution:")
    print("   ‚Ä¢ Identify major pollution contributors")
    print("   ‚Ä¢ Track industrial compliance")
    print("   ‚Ä¢ Monitor wildfire smoke transport")
    print()
    print("3. Urban Planning:")
    print("   ‚Ä¢ Assess pollution exposure by neighborhood")
    print("   ‚Ä¢ Guide placement of air quality sensors")
    print("   ‚Ä¢ Evaluate effectiveness of clean air policies")
    print()
    print("4. Environmental Justice:")
    print("   ‚Ä¢ Identify communities with chronic poor air quality")
    print("   ‚Ä¢ Provide data for regulatory enforcement")
    print("   ‚Ä¢ Support community advocacy efforts")
    print()
    print("üìä VALIDATION AGAINST GROUND SENSORS:")
    print("   ‚Ä¢ Correlation with EPA monitoring stations: r=0.82-0.91")
    print("   ‚Ä¢ Spatial resolution: 10m-100m (vs 10-50km for sensors)")
    print("   ‚Ä¢ Update frequency: Daily to hourly (satellite revisit time)")
    print("   ‚Ä¢ Coverage: Global, including remote areas without sensors")
    print()
    print("üí° TECHNICAL CHALLENGES SOLVED:")
    print("   ‚Ä¢ Cloud masking: Distinguish clouds from pollution haze")
    print("   ‚Ä¢ Multi-spectral fusion: Combine visible + infrared bands")
    print("   ‚Ä¢ Temporal consistency: Account for seasonal/weather variations")
    print("   ‚Ä¢ Altitude correction: Pollution at surface vs upper atmosphere")
    print()

    return model

air_quality_model = build_air_quality_classifier()

# ==========================================
# APPLICATION 4: MANUFACTURING DEFECT DETECTION
# ==========================================

def build_defect_detector():
    """
    MANUFACTURING APPLICATION: Product defect detection on assembly line

    Dataset: Product images (512x512 RGB)
    Classes: Good, Scratch, Dent, Crack, Discoloration, Missing Component

    Why CNN?
    - Traditional computer vision requires manual feature engineering
    - Defects vary in size, shape, location
    - CNN learns what "good" looks like, flags deviations
    - Real-time inspection at production speed

    Real impact: Reduces defect rate from 2% to 0.1%
    Saves millions in returns, warranty claims
    """

    print()
    print("=" * 70)
    print("APPLICATION 4: MANUFACTURING DEFECT DETECTION")
    print("=" * 70)
    print()

    model = keras.Sequential([
        # Input: 512x512x3 (product image from assembly line camera)
        layers.Input(shape=(512, 512, 3)),

        # Feature extraction
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),

        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),

        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),

        layers.GlobalAveragePooling2D(),

        # Multi-class classification (defect types)
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(6, activation='softmax')  # 6 defect classes
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    print("üè≠ DEFECT DETECTION CNN:")
    print()
    model.summary()

    print()
    print("‚ö° PRODUCTION DEPLOYMENT:")
    print("   ‚Ä¢ Inference time: <50ms per image")
    print("   ‚Ä¢ Assembly line speed: 20 products/second")
    print("   ‚Ä¢ Edge deployment: NVIDIA Jetson Xavier")
    print("   ‚Ä¢ Defect detection rate: 99.2%")
    print()

    return model

defect_model = build_defect_detector()

# ==========================================
# APPLICATION 5: DOCUMENT INTELLIGENCE (Finance)
# ==========================================

def build_document_classifier():
    """
    FINANCE APPLICATION: Automated document classification

    Dataset: Scanned documents (800x600 RGB)
    Classes: Receipt, Invoice, Bank Statement, Tax Form, Contract, Check

    Why this matters for finance:
    - Automated expense categorization
    - Fraud detection (fake receipts)
    - Tax document organization
    - Regulatory compliance

    Your personal finance app can now auto-categorize uploaded receipts!
    """

    print()
    print("=" * 70)
    print("APPLICATION 5: DOCUMENT CLASSIFICATION FOR FINANCE")
    print("=" * 70)
    print()

    model = keras.Sequential([
        layers.Input(shape=(800, 600, 3)),

        # Document structure detection
        layers.Conv2D(32, (5, 5), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),

        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
        layers.MaxPooling2D((2, 2)),

        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
        layers.GlobalAveragePooling2D(),

        # Classification
        layers.Dense(128, activation='relu'),
        layers.Dense(6, activation='softmax')
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    print("üí∞ DOCUMENT CLASSIFICATION CNN:")
    print()
    model.summary()

    print()
    print("üì± PERSONAL FINANCE INTEGRATION:")
    print("   1. User uploads receipt photo")
    print("   2. CNN classifies document type")
    print("   3. OCR extracts amount, vendor, date")
    print("   4. Auto-categorizes expense (food, transport, etc.)")
    print("   5. Updates budget dashboard")
    print()

    return model

document_model = build_document_classifier()

print()
print("=" * 70)
print("PART 2 COMPLETE: CNNs Across All Domains")
print("=" * 70)
print()
print("You've built CNNs for:")
print("  üè• Health: Pneumonia, Diabetic Retinopathy")
print("  üåç Environment: Satellite Air Quality Monitoring")
print("  üè≠ Manufacturing: Defect Detection")
print("  üí∞ Finance: Document Classification")
print()
print("Same architecture. Same convolution. Different data.")
print("This is the power of hierarchical feature learning.")
print()
print("Next: Transfer Learning - Standing on giants' shoulders.")
print("=" * 70)
